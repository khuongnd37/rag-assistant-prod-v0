# ü§ñ RAG Assistant - H·ªá Th·ªëng H·ªèi ƒê√°p Th√¥ng Minh v·ªõi VNG Cloud

**RAG Assistant** l√† m·ªôt h·ªá th·ªëng h·ªèi ƒë√°p th√¥ng minh doanh nghi·ªáp ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi ki·∫øn tr√∫c Retrieval-Augmented Generation (RAG), t√≠ch h·ª£p c√°c c√¥ng ngh·ªá ti√™n ti·∫øn bao g·ªìm VNG Cloud OpenSearch, Ollama DeepSeek R1 8B, v√† VNG Cloud S3 Storage.

## **‚ú® T√≠nh NƒÉng Ch√≠nh**

**üîê H·ªá Th·ªëng X√°c Th·ª±c B·∫£o M·∫≠t:**
- ƒêƒÉng nh·∫≠p v·ªõi session management v√† timeout t·ª± ƒë·ªông (8 gi·ªù)
- Ph√¢n quy·ªÅn Admin/User v·ªõi rate limiting ch·ªëng brute force
- Qu·∫£n l√Ω ng∆∞·ªùi d√πng qua Kubernetes Secret ho·∫∑c environment variables

**üìÑ X·ª≠ L√Ω T√†i Li·ªáu ƒêa D·∫°ng:**
- H·ªó tr·ª£ ƒë·ªãnh d·∫°ng: PDF, DOCX, TXT (t·ªëi ƒëa 50MB)
- T·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i t√†i li·ªáu (h·ªçc thu·∫≠t, ph√°p l√Ω, kinh doanh)
- Smart chunking v·ªõi overlap t·ªëi ∆∞u cho RAG
- Fallback strategies cho c√°c th∆∞ vi·ªán x·ª≠ l√Ω t√†i li·ªáu

**ü§ñ AI Th√¥ng Minh Multi-Strategy:**
- **RAG thu·∫ßn:** Tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu ch·∫•t l∆∞·ª£ng cao
- **Hybrid approach:** K·∫øt h·ª£p t√†i li·ªáu + ki·∫øn th·ª©c chung
- **General knowledge:** S·ª≠ d·ª•ng ki·∫øn th·ª©c chung khi kh√¥ng c√≥ t√†i li·ªáu li√™n quan
- Embedding v·ªõi SentenceTransformers all-MiniLM-L6-v2

**‚òÅÔ∏è T√≠ch H·ª£p VNG Cloud:**
- **Vector Database:** VNG Cloud OpenSearch cho semantic search
- **File Storage:** VNG Cloud S3 (vStorage) cho qu·∫£n l√Ω t√†i li·ªáu
- **Kubernetes-ready:** ConfigMap, Secret, v√† Health Check

## **üèóÔ∏è Ki·∫øn Tr√∫c H·ªá Th·ªëng**

```mermaid
graph TD
    A[Ng∆∞·ªùi d√πng] --> B[Streamlit UI]
    B --> C[Auth System]
    B --> D[Document Processor]
    B --> E[RAG Pipeline]
    
    D --> F[VNG Cloud S3]
    E --> G[VNG Cloud OpenSearch]
    E --> H[Ollama DeepSeek R1 8B]
    
    I[Kubernetes Cluster] --> B
    I --> H
    I --> J[Secrets & ConfigMaps]
```

## **‚öôÔ∏è Y√™u C·∫ßu H·ªá Th·ªëng**

**M√¥i Tr∆∞·ªùng Ph√°t Tri·ªÉn:**
- Python 3.9+
- Docker & Docker Compose
- Kubernetes cluster v·ªõi kubectl
- Git

**D·ªãch V·ª• VNG Cloud:**
- OpenSearch instance ƒë√£ c·∫•u h√¨nh
- S3 bucket v·ªõi access credentials
- Network connectivity t·ª´ K8s cluster

**T√†i Nguy√™n T·ªëi Thi·ªÉu:**
- **Streamlit App:** 2 CPU cores, 4GB RAM
- **Ollama:** 4 CPU cores, 8GB RAM, 20GB storage
- **Network:** Stable internet connection

## **üöÄ C√†i ƒê·∫∑t v√† Tri·ªÉn Khai**

### **B∆∞·ªõc 1: Chu·∫©n B·ªã M√¥i Tr∆∞·ªùng**

**Clone Repository:**
```bash
git clone <repository-url>
cd rag-assistant
```

**T·∫°o Virtual Environment:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ho·∫∑c
venv\Scripts\activate     # Windows
```

**C√†i ƒê·∫∑t Dependencies:**
```bash
pip install -r requirements.txt
```

### **B∆∞·ªõc 2: C·∫•u H√¨nh Environment Variables**

**T·∫°o file `.env`:**
```bash
# OpenSearch Configuration
OPENSEARCH_URL=https://phuongtra-93356-9qzuu-hcm03.vdb-opensearch.vngcloud.vn:9200
OPENSEARCH_USER=master-user
OPENSEARCH_PASS=XXXXXXX
OPENSEARCH_INDEX=phuongtra

# Ollama Configuration v·ªõi DeepSeek R1 8B
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:8b

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIM=384

# RAG Settings
RAG_TOP_K=5

# Document Processing
chunk_size=1000
chunk_overlap=200

# VNG Cloud S3 Configuration
S3_ENDPOINT_URL=https://hcm03.vstorage.vngcloud.vn
S3_BUCKET_NAME=ai-data
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_DEFAULT_REGION=hcm03

# Authentication Users
STREAMLIT_USERS={"admin":"admin123","phuongtra":"phuongtra789"}
```

### **B∆∞·ªõc 3: C√†i ƒê·∫∑t Ollama v·ªõi DeepSeek R1 8B**

**C√†i ƒë·∫∑t Ollama:**
```bash
# C√†i ƒë·∫∑t Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Ho·∫∑c s·ª≠ d·ª•ng Docker
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

**Pull DeepSeek R1 8B Model:**
```bash
# Local installation
ollama pull deepseek-r1:8b

# Docker installation
docker exec -it ollama ollama pull deepseek-r1:8b

# Verify model
ollama list
```

### **B∆∞·ªõc 4: Test ·ª®ng D·ª•ng Local**

**Ch·∫°y Streamlit App:**
```bash
streamlit run main.py --server.port 8501
```

**Ki·ªÉm Tra K·∫øt N·ªëi:**
- Truy c·∫≠p: `http://localhost:8501`
- ƒêƒÉng nh·∫≠p v·ªõi: `admin/admin123`
- Upload file test v√† th·ª≠ h·ªèi ƒë√°p

### **B∆∞·ªõc 5: Build Docker Image**

**T·∫°o Dockerfile:**
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8501

# Health check
HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health || exit 1

# Run application
CMD ["streamlit", "run", "main.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**Build v√† Push Image:**
```bash
# Build image
docker build -t your-registry/rag-assistant:latest .

# Test locally
docker run -p 8501:8501 --env-file .env your-registry/rag-assistant:latest

# Push to registry
docker push your-registry/rag-assistant:latest
```

## **‚ò∏Ô∏è Deploy tr√™n Kubernetes**

### **B∆∞·ªõc 1: T·∫°o Namespace**

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: rag-system
```

### **B∆∞·ªõc 2: T·∫°o Secrets**

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: rag-secrets
  namespace: rag-system
type: Opaque
stringData:
  # OpenSearch Credentials
  OPENSEARCH_USER: "master-user"
  OPENSEARCH_PASS: "XXXXXXXX"
  
  # VNG Cloud S3 Credentials
  AWS_ACCESS_KEY_ID: "your-access-key"
  AWS_SECRET_ACCESS_KEY: "your-secret-key"
  
  # User Authentication
  STREAMLIT_USERS: '{"admin":"admin123","phuongtra":"phuongtra789"}'
```

### **B∆∞·ªõc 3: T·∫°o ConfigMap**

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: rag-config
  namespace: rag-system
data:
  # OpenSearch Configuration
  OPENSEARCH_URL: "https://phuongtra-93356-9qzuu-hcm03.vdb-opensearch.vngcloud.vn:9200"
  OPENSEARCH_INDEX: "phuongtra"
  
  # Ollama Configuration
  OLLAMA_URL: "http://ollama-service.rag-system.svc.cluster.local:11434"
  OLLAMA_MODEL: "deepseek-r1:8b"
  
  # Embedding Configuration
  EMBEDDING_MODEL: "sentence-transformers/all-MiniLM-L6-v2"
  EMBEDDING_DIM: "384"
  
  # RAG Settings
  RAG_TOP_K: "5"
  chunk_size: "1000"
  chunk_overlap: "200"
  
  # VNG Cloud S3 Configuration
  S3_ENDPOINT_URL: "https://hcm03.vstorage.vngcloud.vn"
  S3_BUCKET_NAME: "ai-data"
  AWS_DEFAULT_REGION: "hcm03"
```

### **B∆∞·ªõc 4: Deploy Ollama v·ªõi DeepSeek R1 8B**

**PersistentVolumeClaim:**
```yaml
# k8s/ollama-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama-pvc
  namespace: rag-system
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 25Gi  # DeepSeek R1 8B c·∫ßn ~8GB + buffer
  storageClassName: standard
```

**Ollama Deployment:**
```yaml
# k8s/ollama-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-deployment
  namespace: rag-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      initContainers:
      - name: pull-model
        image: ollama/ollama:latest
        command: 
          - /bin/bash
          - -c
          - |
            ollama serve &
            sleep 10
            ollama pull deepseek-r1:8b
            pkill ollama
        volumeMounts:
        - name: ollama-data
          mountPath: /root/.ollama
        env:
        - name: OLLAMA_HOST
          value: "0.0.0.0"
      containers:
      - name: ollama
        image: ollama/ollama:latest
        ports:
        - containerPort: 11434
        env:
        - name: OLLAMA_HOST
          value: "0.0.0.0"
        volumeMounts:
        - name: ollama-data
          mountPath: /root/.ollama
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
        livenessProbe:
          httpGet:
            path: /api/tags
            port: 11434
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /api/tags
            port: 11434
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: ollama-data
        persistentVolumeClaim:
          claimName: ollama-pvc
```

**Ollama Service:**
```yaml
# k8s/ollama-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ollama-service
  namespace: rag-system
spec:
  selector:
    app: ollama
  ports:
    - protocol: TCP
      port: 11434
      targetPort: 11434
  type: ClusterIP
```

### **B∆∞·ªõc 5: Deploy RAG Assistant**

**Deployment:**
```yaml
# k8s/rag-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-assistant
  namespace: rag-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: rag-assistant
  template:
    metadata:
      labels:
        app: rag-assistant
    spec:
      containers:
      - name: rag-assistant
        image: your-registry/rag-assistant:latest
        ports:
        - containerPort: 8501
        envFrom:
        - configMapRef:
            name: rag-config
        - secretRef:
            name: rag-secrets
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /_stcore/health
            port: 8501
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /_stcore/health
            port: 8501
          initialDelaySeconds: 10
          periodSeconds: 5
```

**Service:**
```yaml
# k8s/rag-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: rag-assistant-service
  namespace: rag-system
spec:
  selector:
    app: rag-assistant
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8501
  type: LoadBalancer  # ho·∫∑c NodePort, ClusterIP + Ingress
```

**Ingress (T√πy ch·ªçn):**
```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rag-assistant-ingress
  namespace: rag-system
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: rag-assistant.your-domain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: rag-assistant-service
            port:
              number: 80
```

### **B∆∞·ªõc 6: Deploy All Resources**

```bash
# Apply t·∫•t c·∫£ resources theo th·ª© t·ª±
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/secrets.yaml
kubectl apply -f k8s/configmap.yaml

# Deploy Ollama
kubectl apply -f k8s/ollama-pvc.yaml
kubectl apply -f k8s/ollama-deployment.yaml
kubectl apply -f k8s/ollama-service.yaml

# ƒê·ª£i Ollama ready
kubectl wait --for=condition=ready pod -l app=ollama -n rag-system --timeout=300s

# Deploy RAG Assistant
kubectl apply -f k8s/rag-deployment.yaml
kubectl apply -f k8s/rag-service.yaml
kubectl apply -f k8s/ingress.yaml  # n·∫øu s·ª≠ d·ª•ng
```

## **üìã S·ª≠ D·ª•ng H·ªá Th·ªëng**

### **ƒêƒÉng Nh·∫≠p**
1. Truy c·∫≠p URL c·ªßa ·ª©ng d·ª•ng
2. S·ª≠ d·ª•ng t√†i kho·∫£n m·∫∑c ƒë·ªãnh:
   - **Admin:** `admin/admin123`
   - **User:** `phuongtra/phuongtra789`

### **Qu·∫£n L√Ω T√†i Li·ªáu**
1. **Upload Local:** Ch·ªçn file PDF/DOCX/TXT t·ª´ m√°y t√≠nh
2. **VNG Cloud S3:** Duy·ªát v√† ch·ªçn file t·ª´ S3 bucket
3. H·ªá th·ªëng t·ª± ƒë·ªông x·ª≠ l√Ω v√† t·∫°o embeddings

### **H·ªèi ƒê√°p Th√¥ng Minh**
1. Nh·∫≠p c√¢u h·ªèi v√†o chat interface
2. H·ªá th·ªëng s·∫Ω:
   - T√¨m ki·∫øm semantic trong t√†i li·ªáu
   - Ch·ªçn strategy ph√π h·ª£p (RAG/Hybrid/General)
   - T·∫°o c√¢u tr·∫£ l·ªùi v·ªõi ngu·ªìn tham kh·∫£o

## **üîç Monitoring v√† Troubleshooting**

### **Health Checks**
```bash
# Ki·ªÉm tra pods
kubectl get pods -n rag-system

# Xem logs
kubectl logs -f deployment/rag-assistant -n rag-system
kubectl logs -f deployment/ollama-deployment -n rag-system

# Ki·ªÉm tra services
kubectl get svc -n rag-system

# Test Ollama API
kubectl exec -it deployment/rag-assistant -n rag-system -- curl http://ollama-service:11434/api/tags
```

### **Common Issues v√† Solutions**

**Ollama Model Loading Issues:**
```bash
# Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c pull ch∆∞a
kubectl exec -it deployment/ollama-deployment -n rag-system -- ollama list

# Re-pull model n·∫øu c·∫ßn
kubectl exec -it deployment/ollama-deployment -n rag-system -- ollama pull deepseek-r1:8b
```

**OpenSearch Connection Issues:**
```bash
# Test connectivity
kubectl exec -it deployment/rag-assistant -n rag-system -- curl -v https://phuongtra-93356-9qzuu-hcm03.vdb-opensearch.vngcloud.vn:9200
```

**Memory Issues:**
```bash
# TƒÉng resource limits
kubectl patch deployment rag-assistant -n rag-system -p '{"spec":{"template":{"spec":{"containers":[{"name":"rag-assistant","resources":{"limits":{"memory":"8Gi","cpu":"4000m"}}}]}}}}'
```

### **Performance Tuning**

**Scaling:**
```bash
# Manual scaling
kubectl scale deployment rag-assistant --replicas=5 -n rag-system

# Auto scaling
kubectl autoscale deployment rag-assistant --cpu-percent=70 --min=2 --max=10 -n rag-system
```

**Resource Optimization:**
- ƒêi·ªÅu ch·ªânh `chunk_size` v√† `chunk_overlap` trong ConfigMap
- T·ªëi ∆∞u `RAG_TOP_K` d·ª±a tr√™n quality/performance trade-off
- Monitor memory usage v√† adjust limits

## **üîí Security Best Practices**

**Secrets Management:**
- S·ª≠ d·ª•ng Kubernetes Secrets cho sensitive data
- ƒê·ªãnh k·ª≥ rotate credentials
- Implement proper RBAC

**Network Security:**
- S·ª≠ d·ª•ng NetworkPolicies ƒë·ªÉ restrict traffic
- Enable TLS/SSL cho t·∫•t c·∫£ endpoints
- Implement proper Ingress security

**Monitoring v√† Auditing:**
```bash
# Monitor access logs
kubectl logs -f deployment/rag-assistant -n rag-system | grep "login\|auth"

# Resource monitoring
kubectl top pods -n rag-system
kubectl top nodes
```

## **üìä Backup v√† Recovery**

**Backup OpenSearch Data:**
```bash
# T·∫°o snapshot repository (n·∫øu ch∆∞a c√≥)
curl -X PUT "https://your-opensearch-endpoint/_snapshot/backup_repo" -H 'Content-Type: application/json' -d'
{
  "type": "s3",
  "settings": {
    "bucket": "your-backup-bucket",
    "region": "hcm03",
    "base_path": "opensearch-snapshots"
  }
}'

# T·∫°o snapshot
curl -X PUT "https://your-opensearch-endpoint/_snapshot/backup_repo/snapshot_$(date +%Y%m%d_%H%M%S)"
```

**Backup Kubernetes Configs:**
```bash
kubectl get all,configmap,secret -n rag-system -o yaml > rag-system-backup.yaml
```

## **üîß C·∫•u Tr√∫c Project**

```
rag-assistant/
‚îú‚îÄ‚îÄ auth.py                 # H·ªá th·ªëng x√°c th·ª±c
‚îú‚îÄ‚îÄ config.py              # C·∫•u h√¨nh chung
‚îú‚îÄ‚îÄ document_processor.py  # X·ª≠ l√Ω t√†i li·ªáu
‚îú‚îÄ‚îÄ main.py               # Streamlit app ch√≠nh
‚îú‚îÄ‚îÄ rag_pipeline.py       # Logic RAG
‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îú‚îÄ‚îÄ s3_client.py         # VNG Cloud S3 client
‚îú‚îÄ‚îÄ vector_db.py         # OpenSearch client
‚îú‚îÄ‚îÄ Dockerfile           # Docker build
‚îî‚îÄ‚îÄ k8s/                 # Kubernetes manifests
    ‚îú‚îÄ‚îÄ namespace.yaml
    ‚îú‚îÄ‚îÄ secrets.yaml
    ‚îú‚îÄ‚îÄ configmap.yaml
    ‚îú‚îÄ‚îÄ ollama-pvc.yaml
    ‚îú‚îÄ‚îÄ ollama-deployment.yaml
    ‚îú‚îÄ‚îÄ ollama-service.yaml
    ‚îú‚îÄ‚îÄ rag-deployment.yaml
    ‚îú‚îÄ‚îÄ rag-service.yaml
    ‚îî‚îÄ‚îÄ ingress.yaml
```

## **üéØ Next Steps v√† M·ªü R·ªông**

**T√≠ch H·ª£p N√¢ng Cao:**
- LDAP/SSO authentication
- Multi-tenant support
- Advanced RAG techniques (re-ranking, query expansion)

**Monitoring v√† Observability:**
- Prometheus metrics
- Grafana dashboards
- Distributed tracing

**Performance Optimization:**
- Model quantization
- Caching strategies
- Load balancing optimization

---

**üìû H·ªó Tr·ª£ v√† Li√™n H·ªá**

- **Documentation:** [Internal Wiki/Docs]
- **Issues:** [GitHub Issues]
- **Support:** [Internal Support Channel]

**üè∑Ô∏è Version:** RAG Assistant v2.0  
**üîí Security:** Enterprise-grade with VNG Cloud Integration  
**‚ö° Performance:** Optimized for DeepSeek R1 8B Model